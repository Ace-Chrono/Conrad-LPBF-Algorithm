{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries and Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from zipfile import ZipFile\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import  Dense\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "#import PyDAQmx as nidaq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Camera Card with PyDAQmx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very theoretical, unable to actually test, please don't run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nidaq.Task()\n",
    "t.CreateAIVoltageChan(\"Dev1/ai0\", None, nidaq.DAQmx_Val_Diff, 0, 10, nidaq.DAQmx_Val_Volts, None)\n",
    "t.CfgSampClkTiming(\"\", 1000, nidaq.DAQmx_Val_Rising, nidaq.DAQmx_Val_FiniteSamps, 5000)\n",
    "t.StartTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((5000,), dtype=np.float64)\n",
    "read = nidaq.int32()\n",
    "t.ReadAnalogF64(5000, 0.002, nidaq.DAQmx_Val_GroupByChannel,\n",
    "   data, len(data), nidaq.byref(read), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Images Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_path = r'C:\\Users\\richa_0\\Downloads\\In-situ Meas Data.zip'\n",
    "meltpool_folder = 'In-situ Meas Data/Melt Pool Camera'\n",
    "Layer_folder = 'In-situ Meas Data/Layer Camera'\n",
    "\n",
    "\"\"\"\n",
    "command_path = r'C:\\Users\\richa_0\\Downloads\\Build Command Data.zip'\n",
    "AM_Gcode_folder = 'Build Command Data/AM Gcode' #Note that the AM Gcode is not intended for general use\n",
    "XYPT_folder = 'Build Command Data/XYPT Commands'\n",
    "\n",
    "original_commands = pd.read_csv(r'C:\\Users\\richa_0\\Downloads\\T500_3D_Scan_Strategies_fused_layer0025.csv')\n",
    "new_column_names = ['x', 'y', 'power', 'time']\n",
    "original_commands.columns = new_column_names\n",
    "image_commands = np.array([])\n",
    "for i, row in original_commands.iterrows():\n",
    "    if row['time'] == 2:\n",
    "        image_commands = np.append(image_commands, i)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(zip_ref, file_prefix):\n",
    "    files = [file for file in zip_ref.namelist() if file.startswith(file_prefix) and file.endswith('.bmp')]\n",
    "    images = []\n",
    "    for file in files:\n",
    "        with zip_ref.open(file) as file_data:\n",
    "            # Load image using OpenCV\n",
    "            image_cv2 = cv2.imdecode(np.frombuffer(file_data.read(), np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "            image_cv2 = np.clip(image_cv2, 0, 255).astype(np.uint8)\n",
    "            # Resize and normalize the image\n",
    "            resized_image = cv2.resize(image_cv2, (120, 128))\n",
    "            normalized_image = resized_image / 255.0\n",
    "            images.append(normalized_image)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "with ZipFile(meas_path, 'r') as zip_ref:\n",
    "    train_set = load_and_preprocess_data(zip_ref, \"In-situ Meas Data/Melt Pool Camera/MIA_L0001\")\n",
    "    validation_set = load_and_preprocess_data(zip_ref, \"In-situ Meas Data/Melt Pool Camera/MIA_L0013\")\n",
    "    test_set = load_and_preprocess_data(zip_ref, \"In-situ Meas Data/Melt Pool Camera/MIA_L0025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_area_meltpool(meltpool_image):\n",
    "    meltpool_image = (meltpool_image * 255).astype(np.uint8)\n",
    "    _, binary_image_80 = cv2.threshold(meltpool_image, 150, 255, cv2.THRESH_BINARY)\n",
    "    contours_80, _ = cv2.findContours(binary_image_80, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #contour_image_80 = np.zeros_like(meltpool_image)\n",
    "    #contour_image_80 = cv2.drawContours(contour_image_80, contours_80, -1, (255), 1)\n",
    "    contour_area_80 = []\n",
    "    for contour in contours_80:\n",
    "        area = cv2.contourArea(contour)\n",
    "        contour_area_80.append(area)\n",
    "    total_area_mm = sum(contour_area_80) * 0.000065\n",
    "    return total_area_mm\n",
    "\n",
    "def get_area_list(train_set):\n",
    "    area_label_list = []\n",
    "    for image in train_set:\n",
    "        area_label_list.append(find_area_meltpool(image))\n",
    "    area_label_list = np.array(area_label_list)\n",
    "    return area_label_list\n",
    "\n",
    "def classify_area_meltpool(area_label_list):\n",
    "    area_classification_list = []\n",
    "    for label in area_label_list:\n",
    "        if label == 0:\n",
    "            area_classification_list.append(0)\n",
    "        elif label < 0.011:\n",
    "            area_classification_list.append(1)\n",
    "        elif 0.011 <= label <= 0.014:\n",
    "            area_classification_list.append(2)\n",
    "        elif label > 0.014:\n",
    "            area_classification_list.append(3)\n",
    "        else:\n",
    "            area_classification_list.append(\"Unknown\")\n",
    "    area_classification_list = np.array(area_classification_list)\n",
    "    return area_classification_list\n",
    "\n",
    "def downsize_images(train_set):\n",
    "    resized_images = []\n",
    "    for i in range(len(train_set)):\n",
    "        resized_images.append(cv2.resize(train_set[i], (30, 32)))\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_areas = get_area_list(train_set)\n",
    "train_classifications = classify_area_meltpool(train_areas)\n",
    "downsized_train = downsize_images(train_set)\n",
    "\n",
    "validation_areas = get_area_list(validation_set)\n",
    "validation_classifications = classify_area_meltpool(validation_areas)\n",
    "downsized_validation = downsize_images(validation_set)\n",
    "\n",
    "test_areas = get_area_list(test_set)\n",
    "test_classifications = classify_area_meltpool(test_areas)\n",
    "\n",
    "downsized_test = downsize_images(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 30, 1)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(downsized_train, train_classifications, epochs=10, validation_data=(downsized_validation, validation_classifications))\n",
    "\n",
    "predictions = model.predict(downsized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1000]\n",
    "\n",
    "predictions_number = np.argmax(np.array(predictions), axis=1)\n",
    "predictions_number[1000]\n",
    "\n",
    "counts = np.bincount(predictions_number.astype(int))\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Create a bar chart\n",
    "labels = ['No Meltpool', 'Small', 'Normal', 'Large']\n",
    "plt.bar(labels, counts[0:len(labels)])\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of predicted meltpool sizes')\n",
    "plt.show()\n",
    "\n",
    "counts = np.bincount(test_classifications.astype(int))\n",
    "\n",
    "# Create a bar chart\n",
    "labels = ['No Meltpool', 'Small', 'Normal', 'Large']\n",
    "plt.bar(labels, counts[0:len(labels)])\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of actual meltpool sizes')\n",
    "plt.show()\n",
    "\n",
    "wrong_predictions = np.where(predictions_number != test_classifications)[0]\n",
    "\n",
    "# Count the number of correct and wrong predictions\n",
    "num_correct = len(test_classifications) - len(wrong_predictions)\n",
    "num_wrong = len(wrong_predictions)\n",
    "\n",
    "# Data for the bar chart\n",
    "labels = ['Correct Predictions', 'Wrong Predictions']\n",
    "values = [num_correct, num_wrong]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, values, color=['green', 'red'])\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Number of Predictions')\n",
    "ax.set_title('Correct and Wrong Predictions')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "correct_predictions = np.sum(predictions_number == test_classifications)\n",
    "\n",
    "# Calculate the total number of predictions\n",
    "total_predictions = len(test_classifications)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
